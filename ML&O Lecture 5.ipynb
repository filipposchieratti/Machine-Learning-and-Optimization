{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #easy plotting: subpackage of seaborn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Plotting the ROC curve\n",
    "\n",
    "We work with the same Default dataset as the previous session.\n",
    "\n",
    "1. Run the code below to get back to the same spot as last session: i.e., with X and Y defined at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please import dataset on Google Colab\n",
    "Default=pd.read_csv(\"Default.csv\")\n",
    "Default=pd.get_dummies(Default,drop_first=True,columns=[\"default\",\"student\"])\n",
    "Y=Default[\"default_Yes\"]\n",
    "X=Default.drop(columns=[\"default_Yes\",\"income\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use `train_test_split` twice to divide `X` and `Y` into three sets: training (50%), test(25%), validation (25%). You should get `Xtrain,ytrain` and `Xval, yval` and `Xtest, ytest` with appropriate sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xother, ytrain, yother= train_test_split(X,Y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval, Xtest, yval, ytest=train_test_split(Xother,yother, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n",
      "(2500, 2)\n",
      "(2500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(Xval.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit a logistic regression model to `Xtrain, ytrain` as done in the last session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = LogisticRegression().fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Predict the **probability of defaulting** for the validation set. Call this `y_pred`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logm.predict_proba(Xval)[:,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run the following code. What do you think roccurve is giving you? How would you use this to obtain the curve seen in class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.14593698e-04,\n",
       "        4.14593698e-04, 8.29187396e-04, 8.29187396e-04, 1.24378109e-03,\n",
       "        1.24378109e-03, 1.65837479e-03, 1.65837479e-03, 2.48756219e-03,\n",
       "        2.48756219e-03, 2.90215589e-03, 2.90215589e-03, 3.31674959e-03,\n",
       "        3.31674959e-03, 3.73134328e-03, 3.73134328e-03, 4.14593698e-03,\n",
       "        4.14593698e-03, 4.56053068e-03, 4.56053068e-03, 5.80431177e-03,\n",
       "        5.80431177e-03, 6.21890547e-03, 6.21890547e-03, 7.46268657e-03,\n",
       "        7.46268657e-03, 7.87728027e-03, 7.87728027e-03, 1.03648425e-02,\n",
       "        1.03648425e-02, 1.16086235e-02, 1.16086235e-02, 1.20232172e-02,\n",
       "        1.20232172e-02, 1.28524046e-02, 1.28524046e-02, 1.78275290e-02,\n",
       "        1.78275290e-02, 1.94859038e-02, 1.94859038e-02, 2.03150912e-02,\n",
       "        2.03150912e-02, 2.40464345e-02, 2.40464345e-02, 2.52902156e-02,\n",
       "        2.52902156e-02, 2.57048093e-02, 2.57048093e-02, 3.48258706e-02,\n",
       "        3.48258706e-02, 3.73134328e-02, 3.73134328e-02, 3.89718076e-02,\n",
       "        3.89718076e-02, 4.43615257e-02, 4.43615257e-02, 4.47761194e-02,\n",
       "        4.47761194e-02, 4.68490879e-02, 4.68490879e-02, 4.89220564e-02,\n",
       "        4.89220564e-02, 5.05804312e-02, 5.05804312e-02, 5.43117745e-02,\n",
       "        5.43117745e-02, 5.80431177e-02, 5.80431177e-02, 6.17744610e-02,\n",
       "        6.17744610e-02, 7.66998342e-02, 7.66998342e-02, 7.75290216e-02,\n",
       "        7.75290216e-02, 7.83582090e-02, 7.83582090e-02, 7.87728027e-02,\n",
       "        7.87728027e-02, 7.91873964e-02, 7.91873964e-02, 8.00165837e-02,\n",
       "        8.00165837e-02, 8.33333333e-02, 8.33333333e-02, 8.58208955e-02,\n",
       "        8.58208955e-02, 9.32835821e-02, 9.32835821e-02, 9.57711443e-02,\n",
       "        9.57711443e-02, 1.10696517e-01, 1.10696517e-01, 1.94859038e-01,\n",
       "        1.94859038e-01, 2.07296849e-01, 2.07296849e-01, 2.22222222e-01,\n",
       "        2.22222222e-01, 2.23880597e-01, 2.23880597e-01, 2.26368159e-01,\n",
       "        2.26368159e-01, 2.55389718e-01, 2.55389718e-01, 2.81509121e-01,\n",
       "        2.81509121e-01, 3.25870647e-01, 3.25870647e-01, 5.96600332e-01,\n",
       "        5.96600332e-01, 9.46102819e-01, 9.90049751e-01, 9.93366501e-01,\n",
       "        1.00000000e+00]),\n",
       " array([0.        , 0.01136364, 0.06818182, 0.06818182, 0.11363636,\n",
       "        0.11363636, 0.125     , 0.125     , 0.15909091, 0.15909091,\n",
       "        0.21590909, 0.21590909, 0.22727273, 0.22727273, 0.23863636,\n",
       "        0.23863636, 0.26136364, 0.26136364, 0.31818182, 0.31818182,\n",
       "        0.35227273, 0.35227273, 0.38636364, 0.38636364, 0.40909091,\n",
       "        0.40909091, 0.42045455, 0.42045455, 0.43181818, 0.43181818,\n",
       "        0.44318182, 0.44318182, 0.45454545, 0.45454545, 0.46590909,\n",
       "        0.46590909, 0.5       , 0.5       , 0.51136364, 0.51136364,\n",
       "        0.53409091, 0.53409091, 0.56818182, 0.56818182, 0.57954545,\n",
       "        0.57954545, 0.60227273, 0.60227273, 0.625     , 0.625     ,\n",
       "        0.64772727, 0.64772727, 0.65909091, 0.65909091, 0.67045455,\n",
       "        0.67045455, 0.68181818, 0.68181818, 0.69318182, 0.69318182,\n",
       "        0.70454545, 0.70454545, 0.71590909, 0.71590909, 0.72727273,\n",
       "        0.72727273, 0.73863636, 0.73863636, 0.75      , 0.75      ,\n",
       "        0.76136364, 0.76136364, 0.77272727, 0.77272727, 0.78409091,\n",
       "        0.78409091, 0.79545455, 0.79545455, 0.80681818, 0.80681818,\n",
       "        0.81818182, 0.81818182, 0.82954545, 0.82954545, 0.84090909,\n",
       "        0.84090909, 0.85227273, 0.85227273, 0.86363636, 0.86363636,\n",
       "        0.875     , 0.875     , 0.88636364, 0.88636364, 0.89772727,\n",
       "        0.89772727, 0.90909091, 0.90909091, 0.92045455, 0.92045455,\n",
       "        0.93181818, 0.93181818, 0.94318182, 0.94318182, 0.95454545,\n",
       "        0.95454545, 0.96590909, 0.96590909, 0.97727273, 0.97727273,\n",
       "        0.98863636, 0.98863636, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ]),\n",
       " array([1.97925361e+00, 9.79253615e-01, 9.39604478e-01, 9.10717628e-01,\n",
       "        8.67326808e-01, 8.66003722e-01, 8.38591616e-01, 8.10058056e-01,\n",
       "        7.74278717e-01, 7.57350341e-01, 7.34629826e-01, 7.20641771e-01,\n",
       "        7.18381533e-01, 7.02221982e-01, 7.00257101e-01, 6.86446830e-01,\n",
       "        6.73580508e-01, 6.50274855e-01, 5.84369494e-01, 5.77488684e-01,\n",
       "        5.57245479e-01, 5.48278431e-01, 5.05993588e-01, 4.81241888e-01,\n",
       "        4.68131694e-01, 4.45796547e-01, 4.42653032e-01, 4.37513756e-01,\n",
       "        4.35242898e-01, 4.29668393e-01, 4.26234536e-01, 3.91710118e-01,\n",
       "        3.74156899e-01, 3.62393994e-01, 3.55110288e-01, 3.53343637e-01,\n",
       "        3.34981023e-01, 3.25479668e-01, 3.24687960e-01, 2.97658269e-01,\n",
       "        2.93765931e-01, 2.76008815e-01, 2.64376727e-01, 2.63189053e-01,\n",
       "        2.62920095e-01, 2.52623242e-01, 2.51994913e-01, 2.46314464e-01,\n",
       "        2.45628684e-01, 2.42974651e-01, 2.34769643e-01, 1.95448629e-01,\n",
       "        1.94234337e-01, 1.80921421e-01, 1.80344246e-01, 1.70227710e-01,\n",
       "        1.68928127e-01, 1.47445674e-01, 1.42945497e-01, 1.41723880e-01,\n",
       "        1.41611387e-01, 1.40266840e-01, 1.37502682e-01, 1.29721340e-01,\n",
       "        1.29710384e-01, 1.24711714e-01, 1.20425464e-01, 1.15007480e-01,\n",
       "        1.14591827e-01, 1.09028870e-01, 1.09014370e-01, 1.05546153e-01,\n",
       "        1.05003554e-01, 7.69795013e-02, 7.61157720e-02, 7.53778820e-02,\n",
       "        7.51367384e-02, 7.43372372e-02, 7.10146722e-02, 7.02140640e-02,\n",
       "        7.01966774e-02, 6.96519657e-02, 6.87992036e-02, 6.82516021e-02,\n",
       "        6.82319474e-02, 6.51376322e-02, 6.31831290e-02, 6.05281466e-02,\n",
       "        6.02101976e-02, 5.57395407e-02, 5.56963405e-02, 5.39591510e-02,\n",
       "        5.39177145e-02, 4.48396838e-02, 4.46528175e-02, 1.80376354e-02,\n",
       "        1.79304949e-02, 1.58794866e-02, 1.58397543e-02, 1.34734819e-02,\n",
       "        1.34488577e-02, 1.33942713e-02, 1.33827393e-02, 1.31175044e-02,\n",
       "        1.30690413e-02, 1.02385615e-02, 1.02384157e-02, 8.14149171e-03,\n",
       "        8.12552431e-03, 5.67988355e-03, 5.61555172e-03, 9.53567829e-04,\n",
       "        9.50886714e-04, 2.22683954e-05, 2.22653429e-05, 1.19231087e-05,\n",
       "        1.09271661e-05]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roccurve=metrics.roc_curve(yval,y_pred)\n",
    "roccurve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use `plt.plot` to recover the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bc7eda05e0>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(roccurve[0], roccurve[1], linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: The ROC, the threshold, and the supervised machine learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use `roccurve` above to pick your favorite threshold bearing in mind that we are okay with 1-specificity being larger than 0, but we would like sensitivity to be close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((roccurve[0]<=0.3) & (roccurve[0]>=0.2)) & (roccurve[1]>=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93243243, 0.94594595])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roccurve[1][((roccurve[0]<=0.3) & (roccurve[0]>=0.2)) & (roccurve[1]>=0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01524048, 0.0152376 ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roccurve[2][((roccurve[0]<=0.3) & (roccurve[0]>=0.2)) & (roccurve[1]>=0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20115416, 0.20115416])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roccurve[0][((roccurve[0]<=0.3) & (roccurve[0]>=0.2)) & (roccurve[1]>=0.9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. With the threshold you've picked, we're now going to work towards our final model. First, we concatenate our training sets and validation sets and retrain our model on these sets. Run the code below to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_val=pd.concat([Xtrain, Xval])\n",
    "ytrain_val=pd.concat([ytrain, yval])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Retrain our model on `Xtrain_val` and `ytrain_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm = LogisticRegression().fit(Xtrain_val, ytrain_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We now evaluate the model on the test set. To do this, predict the probability of defaulting for observations in the test set. Obtain the corresponding labels by thresholding using the threshold you want (here, 0.018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Default_prob=logm.predict_proba(Xtest)[:,1] #predictions of the probabilities on the test data\n",
    "threshold=0.018\n",
    "y_pred=np.where(Default_prob > threshold, 1, 0) #predict the classes for test data based on the threshold found via the validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compute the confusion matrix and the accuracy score. Does this work for you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1960,  443],\n",
       "       [   5,   92]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compute the AUC by running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9536447138671162"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytest, Default_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework - Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. See lecture notes.\n",
    "\n",
    "2. Suppose we were able to predict perfectly the labels: if the label is zero, we would predict zero. If the label is one, we would predict that the label is one. Thus, regardless of the threshold we pick between zero and one strictly, we would build a confusion matrix with no false positives and no false negatives. Because of this the true positive rate (the sensitivity) would be equal to one. The false positive rate (1-the specificity) would be equal to zero. On the ROC, this means that on top of the (0,0) point (corresponding to threshold 1) and the (1,1) point (corresponding to threshold 0), the only other point would be the point (0,1). This gives the first curve and an area under the curve equal to one. \n",
    "\n",
    "3. In this setting, we are not learning anything from the features, just randomly allocating labels to the data.\n",
    "\n",
    "4. Suppose that we have a proportion $p$ of observations that have actual labels that are yes and a proportion $1-p$ that have labels that are no.\n",
    "\n",
    "When faced with picking a label, we have a 50-50 chance. There will be $p/2$ \"yes\" observations that will be correctly classified and $p/2$ that are incorrectly classified, i.e., they are set to \"no\" when they are actually \"yes\": they are false negatives.\n",
    "\n",
    "Likewise, there will be $(1-p)/2$ \"no\" observations that will be correctly classified and $(1-p)/2$ that will be incorrectly classified, i.e., that are set to \"yes\" when they are actually \"no\": these are false positives.\n",
    "\n",
    "This gives rise to the confusion matrix:\n",
    "\n",
    "\n",
    "|  | Predicted No | Predicted Yes |\n",
    "| --- | --- | --- |\n",
    "| Actual No | $(1-p)/2$ | $(1-p)/2$ |\n",
    "| Actual Yes |  $p/2$ | $p/2$ |\n",
    "\n",
    "From this we deduce the specificity:\n",
    "$$specificity=\\frac{(1-p)/2}{(1-p)/2+(1-p)/2}=\\frac12$$\n",
    "and the sensitivity:\n",
    "$$sensitivity=\\frac{p/2}{p/2+p/2}=\\frac12.$$\n",
    "\n",
    "As the point on the ROC curve is given by $(1-specificity, sensitivity)$, it follows that $(1/2,1/2)$ is on the curve.\n",
    "\n",
    "Notice here that the threshold doesn't play a role: we are assigning observations to either \"0\" (no) or \"1\" (yes) immediately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
